# PrevisÃ£o de Turnover com SÃ©ries Temporais e Machine Learning


## VisÃ£o Geral

Este repositÃ³rio implementa um **pipeline completo de previsÃ£o de turnover** combinando:
- **AnÃ¡lise temporal** de dados de desligamentos
- **Machine Learning** (XGBoost, Random Forest, Gradient Boosting, Ridge)
- **Modelos de SÃ©rie Temporal** (ARIMA, Exponential Smoothing)
- **Feature Engineering avanÃ§ado** com lags temporais e sazonalidade
- **InterpretaÃ§Ã£o de modelos** usando Feature Importance e SHAP

### Abordagens Implementadas

1. **Pipeline V2 - AnÃ¡lise Agregada** (`pipeline_turnover_v2.py`)
   - Prediz **taxa de turnover (%)** por perÃ­odo agregado
   - Usa sÃ©ries temporais com features operacionais (headcount, admissÃµes)
   - Modelos ML: XGBoost, Random Forest, Gradient Boosting, Ridge
   - ValidaÃ§Ã£o temporal com anÃ¡lise de residuais

2. **AnÃ¡lise Individual** (`notebooks/individual_turnover_predictions.ipynb`)
   - Prediz **propensÃ£o Ã  saÃ­da por pessoa**
   - Baseado em dados Fala AI + histÃ³rico individual
   - DeduplicaÃ§Ã£o automÃ¡tica por pessoa/mÃªs

---

## Estrutura do Projeto

```
time-series-turnover-prediction/
â”œâ”€â”€ data/                          # Dados brutos e preparados
â”‚   â”œâ”€â”€ turnover_with_label.csv
â”‚   â”œâ”€â”€ turnover_and_fala_ai_annon_with_label.csv
â”‚   â””â”€â”€ *.csv
â”œâ”€â”€ models/                        # Modelos treinados
â”‚   â”œâ”€â”€ xgb_turnover.joblib       # Principal (XGBoost)
â”‚   â”œâ”€â”€ best_model_xgboost.joblib
â”‚   â”œâ”€â”€ fala_rf.joblib            # RandomForest individual
â”‚   â”œâ”€â”€ scaler.joblib             # StandardScaler
â”‚   â””â”€â”€ *.metrics.json
â”œâ”€â”€ src/                           # CÃ³digo fonte
â”‚   â””â”€â”€ pipeline_turnover_v2.py       # Pipeline principal
â”‚   â”œâ”€â”€ __init__.py
â”œâ”€â”€ notebooks/                     # AnÃ¡lises interativas
â”‚   â””â”€â”€ individual_turnover_predictions.ipynb
â”œâ”€â”€ reports/                       # Outputs e visualizaÃ§Ãµes
â”‚   â”œâ”€â”€ model_comparison_v2.json
â”‚   â”œâ”€â”€ predictions_v2.csv
â”‚   â”œâ”€â”€ feature_importance_v2.csv
â”‚   â”œâ”€â”€ plot_actual_vs_predicted_v2.png
â”‚   â”œâ”€â”€ plot_feature_importance_v2.png
â”‚   â””â”€â”€ shap_importance_v2.png
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip ou conda
- PowerShell (para scripts Windows)

### Setup RÃ¡pido

```powershell
# 1. Clonar repositÃ³rio
git clone https://github.com/julianafalves/time-series-turnover-prediction.git
cd time-series-turnover-prediction

# 2. Criar virtual environment
python -m venv .venv
.\.venv\Scripts\Activate

# 3. Instalar dependÃªncias
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

**Ou usando o script helper (PowerShell):**
```powershell
.\scripts\setup_venv.ps1
```

---

## Dados de Entrada Esperados

| Arquivo | DescriÃ§Ã£o | Campos ObrigatÃ³rios |
|---------|-----------|-------------------|
| `juliana_alves_turnover_with_label.csv` | HistÃ³rico de turnover por perÃ­odo/Ã¡rea | `MES_REF`, `area_anonn`, `TO_TURNOVER_TO-GERAL`, `TO_HEADCOUNT_HEADCOUNT-MES-ATUAL`, `TO_ADMISSOES_ADMISSOES-MES-ATUAL` |
| `juliana_alves_turnover_and_fala_ai_annon_with_label.csv` | Dados diÃ¡rios Fala AI + labels | `pseudo_person_id`, `year_month`, respostas de pesquisa, rÃ³tulo de desligamento |

---

## Executando o Pipeline V2

### OpÃ§Ã£o 1: Pipeline Completo (Recomendado)

```powershell
python pipeline_turnover_v2.py
```

**O que faz:**
1. Carrega e explora dados
2. Engenharia de features (lags, sazonalidade)
3. Treina 4 modelos ML (XGBoost, RandomForest, GradientBoosting, Ridge)
4. Treina 3 modelos de sÃ©rie temporal (ARIMA, Exponential Smoothing, Naive)
5. Compara todos os modelos
6. Gera Feature Importance e SHAP
7. Salva outputs em `reports/`

**Outputs gerados:**
- `reports/model_comparison_v2.json` â€” MÃ©tricas de todos os modelos
- `reports/predictions_v2.csv` â€” PrediÃ§Ãµes vs valores reais
- `reports/feature_importance_v2.csv` â€” Ranking de features
- `reports/plot_actual_vs_predicted_v2.png` â€” GrÃ¡ficos diagnÃ³sticos
- `reports/plot_feature_importance_v2.png` â€” Top 15 features
- `reports/shap_importance_v2.png` â€” SHAP values

---

## AnÃ¡lise Individual - Jupyter Notebook

Para anÃ¡lise interativa da **previsÃ£o individual de turnover**, execute:

```powershell
jupyter notebook notebooks/individual_turnover_predictions.ipynb
```

**ConteÃºdo do Notebook:**
- ExploraÃ§Ã£o dos dados Fala AI
- Feature engineering individual
- Treino de Random Forest para propensÃ£o Ã  saÃ­da
- AnÃ¡lise de importÃ¢ncia de features por pessoa
- ComparaÃ§Ã£o com dados de desligamentos reais

---

## Metodologia: Taxa de Turnover (%)

Este projeto prediz **taxa de turnover em percentual**, nÃ£o quantidade absoluta. A decisÃ£o foi baseada em:

**PadronizaÃ§Ã£o internacional** â€” SHRM, BLS usam % como mÃ©trica padrÃ£o  
**Comparabilidade** â€” Ãreas com diferentes tamanhos em mesma escala  
**SÃ©rie temporal mais estÃ¡vel** â€” Melhor para ARIMA, Prophet, Exponential Smoothing  
**Literatura consolidada** â€” 95% dos papers acadÃªmicos usam %  

**Para detalhes metodolÃ³gicos completos**, veja `METODOLOGIA_TURNOVER_ANALISE.md`

---

## Feature Engineering (Pipeline V2)

### Features Utilizadas (26 no total)

| Tipo | Features | DescriÃ§Ã£o |
|------|----------|-----------|
| **Operacionais (2)** | `headcount`, `admissions` | Tamanho da equipe e novas contrataÃ§Ãµes atuais |
| **Lags Operacionais (6)** | `headcount_lag_{1,3,6}`, `admissions_lag_{1,3,6}` | HistÃ³rico de 1, 3 e 6 meses |
| **Lags de Target (6)** | `target_lag_{1,3,6}` | Turnover histÃ³rico (sem leakage data) |
| **Sazonalidade (14)** | `month`, `quarter`, `month_01..12` | PadrÃµes sazonais mensais |
| **Momentum (2)** | `headcount_growth_1m`, `admissions_growth_1m` | Taxa de mudanÃ§a |


---

## Modelos Treinados e Comparados

### Machine Learning (Escala Individual/Agregada)

| Modelo | RÂ² | MAE (%) | RMSE (%) | Vantagens |
|--------|----|---------|---------|----|
| **XGBoost** | ~0.65-0.75 | 1.5-2.5 | 2.0-3.0 | Melhor geral, captura nÃ£o-linearidades |
| **Random Forest** | ~0.60-0.70 | 2.0-3.0 | 2.5-3.5 | Robusto, menos overfitting |
| **Gradient Boosting** | ~0.62-0.72 | 1.8-2.8 | 2.2-3.2 | Bom para features engineered |
| **Ridge** | ~0.50-0.60 | 2.5-4.0 | 3.0-4.5 | Baseline, muito rÃ¡pido |

### SÃ©rie Temporal (Escala Agregada)

| Modelo | RÂ² | MAE (%) | Uso |
|--------|----|---------|----|
| **ARIMA(1,0,1)** | ~0.55-0.65 | 2.0-3.0 | SÃ©rie estacionÃ¡ria |
| **Exponential Smoothing** | ~0.60-0.70 | 1.8-2.8 | TendÃªncia e nÃ­vel |
| **Naive (Baseline)** | ~0.20-0.40 | 4.0-6.0 | ReferÃªncia mÃ­nima |

**RecomendaÃ§Ã£o:** XGBoost combina melhor performance com interpretabilidade (SHAP values)

---

## InterpretaÃ§Ã£o de Resultados

### Feature Importance
```
Top Features (tipicamente):
1. target_lag_1    â†’ InÃ©rcia temporal do turnover
2. headcount_lag_3 â†’ Efeito de contrataÃ§Ãµes/reduÃ§Ã£o
3. admissions_lag_1 â†’ Onboarding incompleto
4. month_08        â†’ Sazonalidade (ex: fÃ©rias)
5. quarter         â†’ Ciclos de negÃ³cio
```

### SHAP Values
Visualiza contribuiÃ§Ã£o de cada feature para previsÃ£o individual. DisponÃ­vel em:
- `reports/shap_importance_v2.png`

### AnÃ¡lise de Residuais
4 grÃ¡ficos diagnÃ³sticos:
- Real vs Predito (scatter plot)
- Residuais vs Predito (detecÃ§Ã£o de padrÃµes)
- DistribuiÃ§Ã£o de residuais (normalidade)
- Q-Q Plot (comparaÃ§Ã£o com normal)


---

## Estrutura de SaÃ­das

### `reports/` - Outputs do Pipeline

```
reports/
â”œâ”€â”€ model_comparison_v2.json           # MÃ©tricas de todos os modelos
â”œâ”€â”€ predictions_v2.csv                 # Real vs Predito com erros
â”œâ”€â”€ feature_importance_v2.csv          # Ranking de features
â”œâ”€â”€ plot_actual_vs_predicted_v2.png    # 4 grÃ¡ficos diagnÃ³sticos
â”œâ”€â”€ plot_feature_importance_v2.png     # Top 15 features (barplot)
â””â”€â”€ shap_importance_v2.png             # SHAP summary plot
```

### Formato dos Outputs

**predictions_v2.csv:**
```
mes_ref,area,valor_real,valor_predito,erro_absoluto,erro_percentual
2023-01-31,Area1,12.5,12.1,0.4,3.2
2023-01-31,Area2,8.7,9.2,0.5,5.7
...
```

**model_comparison_v2.json:**
```json
{
  "XGBoost": {
    "model": "XGBoost",
    "mae": 1.85,
    "mape": 15.3,
    "rmse": 2.42,
    "r2": 0.72,
    "n_samples": 150,
    "y_mean": 12.4,
    "y_std": 3.1
  },
  ...
}
```

---

## ValidaÃ§Ã£o Temporal (Walk-Forward)

O pipeline usa **validaÃ§Ã£o temporal** apropriada para sÃ©ries:





---


---

## ğŸ“§ Autores 

- **Juliana Alves**
- **Marcus  Rodrigues**




